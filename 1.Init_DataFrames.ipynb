{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark = SparkSession.builder.master('local').appName('initDataFrames').enableHiveSupport().getOrCreate()",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.36.59.127:4042\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>initDataFrames</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
            "text/plain": "<pyspark.sql.session.SparkSession at 0x7fc72e1c5a90>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sc=spark.sparkContext",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders = spark.read.csv('data//retail_db//orders.csv')",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Creation of Dataframes in PySpark - Method 1"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark.createDataFrame([(1,)]).show()\n#Creation of dataframes are enabled by list of tuples. Note that while mentioning tuples with one element then we need to specify comma at the end as above.",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+\n| _1|\n+---+\n|  1|\n+---+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Using List"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "l = [('Alice', 1)]\nspark.createDataFrame(l).show()",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+---+\n|   _1| _2|\n+-----+---+\n|Alice|  1|\n+-----+---+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark.createDataFrame(l, ['name', 'age']).show()",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+---+\n| name|age|\n+-----+---+\n|Alice|  1|\n+-----+---+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Using Dictionary"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "d = [{'name': 'Alice', 'age': 1}]",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark.createDataFrame(d).show()",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n  warnings.warn(\"inferring schema from dict is deprecated,\"\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "+---+-----+\n|age| name|\n+---+-----+\n|  1|Alice|\n+---+-----+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Using rdd"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "l = [('Alice', 1)]\nrdd = sc.parallelize(l)\nspark.createDataFrame(rdd).show()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+---+\n|   _1| _2|\n+-----+---+\n|Alice|  1|\n+-----+---+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark.createDataFrame(rdd, ['name', 'age']).show()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+---+\n| name|age|\n+-----+---+\n|Alice|  1|\n+-----+---+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark.createDataFrame(rdd, \"a: string, b: int\").show()",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+---+\n|    a|  b|\n+-----+---+\n|Alice|  1|\n+-----+---+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Using Row"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Person = Row('name', 'age')\nperson = rdd.map(lambda x: Person(*x))\nspark.createDataFrame(person).show()",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+---+\n| name|age|\n+-----+---+\n|Alice|  1|\n+-----+---+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Creation of Pyspark Dataframes - Method 2\n#### By loading the file as RDD and explicitly manipulating the fields and specifying datatypes"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ordersRDD = sc.textFile('data//retail_db//orders.csv')",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders = ordersRDD.map(lambda x:(Row(x.split(',')[0],x.split(',')[1],x.split(',')[2],x.split(',')[3]))).toDF(). \\\n        toDF('order_id','order_date','order_customer_id','order_status')\norders.printSchema()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "root\n |-- order_id: string (nullable = true)\n |-- order_date: string (nullable = true)\n |-- order_customer_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders.show()",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+--------+--------------------+-----------------+---------------+\n|order_id|          order_date|order_customer_id|   order_status|\n+--------+--------------------+-----------------+---------------+\n|order_id|          order_date|order_customer_id|   order_status|\n|       1|2013-07-25 00:00:...|            11599|         CLOSED|\n|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|\n|       3|2013-07-25 00:00:...|            12111|       COMPLETE|\n|       4|2013-07-25 00:00:...|             8827|         CLOSED|\n|       5|2013-07-25 00:00:...|            11318|       COMPLETE|\n|       6|2013-07-25 00:00:...|             7130|       COMPLETE|\n|       7|2013-07-25 00:00:...|             4530|       COMPLETE|\n|       8|2013-07-25 00:00:...|             2911|     PROCESSING|\n|       9|2013-07-25 00:00:...|             5657|PENDING_PAYMENT|\n|      10|2013-07-25 00:00:...|             5648|PENDING_PAYMENT|\n|      11|2013-07-25 00:00:...|              918| PAYMENT_REVIEW|\n|      12|2013-07-25 00:00:...|             1837|         CLOSED|\n|      13|2013-07-25 00:00:...|             9149|PENDING_PAYMENT|\n|      14|2013-07-25 00:00:...|             9842|     PROCESSING|\n|      15|2013-07-25 00:00:...|             2568|       COMPLETE|\n|      16|2013-07-25 00:00:...|             7276|PENDING_PAYMENT|\n|      17|2013-07-25 00:00:...|             2667|       COMPLETE|\n|      18|2013-07-25 00:00:...|             1205|         CLOSED|\n|      19|2013-07-25 00:00:...|             9488|PENDING_PAYMENT|\n+--------+--------------------+-----------------+---------------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Creation of Pyspark Dataframes - Method 3\n#### By loading the file as csv and mentioning the schema"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ordersSchema = StructType([\nStructField('order_id',IntegerType(),False),\nStructField('order_date',TimestampType(),False),\nStructField('order_customer_id',IntegerType(),False),\nStructField('order_status',StringType(),False)\n])\norders = spark.read.csv('data//retail_db//orders.csv',header=True,schema=ordersSchema)\norders.printSchema()",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "root\n |-- order_id: integer (nullable = true)\n |-- order_date: timestamp (nullable = true)\n |-- order_customer_id: integer (nullable = true)\n |-- order_status: string (nullable = true)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders.show()",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+--------+-------------------+-----------------+---------------+\n|order_id|         order_date|order_customer_id|   order_status|\n+--------+-------------------+-----------------+---------------+\n|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n+--------+-------------------+-----------------+---------------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### By loading the file as csv and modify datatypes"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders = spark.read.csv('data//retail_db//orders.csv',header=True).toDF('order_id','order_date','order_customer_id','order_status')\norders.printSchema()",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "root\n |-- order_id: string (nullable = true)\n |-- order_date: string (nullable = true)\n |-- order_customer_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders.withColumn('order_id',orders.order_date.cast('int')).\\\n       withColumn('order_date',orders.order_date.cast('timestamp')).\\\n       withColumn('order_customer_id',orders.order_customer_id.cast('int')).\\\n       withColumn('order_status',orders.order_status.cast('string'))\norders.printSchema()",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "root\n |-- order_id: string (nullable = true)\n |-- order_date: string (nullable = true)\n |-- order_customer_id: string (nullable = true)\n |-- order_status: string (nullable = true)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders.show()",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+--------+--------------------+-----------------+---------------+\n|order_id|          order_date|order_customer_id|   order_status|\n+--------+--------------------+-----------------+---------------+\n|       1|2013-07-25 00:00:...|            11599|         CLOSED|\n|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|\n|       3|2013-07-25 00:00:...|            12111|       COMPLETE|\n|       4|2013-07-25 00:00:...|             8827|         CLOSED|\n|       5|2013-07-25 00:00:...|            11318|       COMPLETE|\n|       6|2013-07-25 00:00:...|             7130|       COMPLETE|\n|       7|2013-07-25 00:00:...|             4530|       COMPLETE|\n|       8|2013-07-25 00:00:...|             2911|     PROCESSING|\n|       9|2013-07-25 00:00:...|             5657|PENDING_PAYMENT|\n|      10|2013-07-25 00:00:...|             5648|PENDING_PAYMENT|\n|      11|2013-07-25 00:00:...|              918| PAYMENT_REVIEW|\n|      12|2013-07-25 00:00:...|             1837|         CLOSED|\n|      13|2013-07-25 00:00:...|             9149|PENDING_PAYMENT|\n|      14|2013-07-25 00:00:...|             9842|     PROCESSING|\n|      15|2013-07-25 00:00:...|             2568|       COMPLETE|\n|      16|2013-07-25 00:00:...|             7276|PENDING_PAYMENT|\n|      17|2013-07-25 00:00:...|             2667|       COMPLETE|\n|      18|2013-07-25 00:00:...|             1205|         CLOSED|\n|      19|2013-07-25 00:00:...|             9488|PENDING_PAYMENT|\n|      20|2013-07-25 00:00:...|             9198|     PROCESSING|\n+--------+--------------------+-----------------+---------------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### By loading the file as csv and inferring schema automatically\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders = spark.read.csv('data//retail_db//orders.csv',header=True,inferSchema=True,sep=',')\norders.printSchema()",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "root\n |-- order_id: integer (nullable = true)\n |-- order_date: timestamp (nullable = true)\n |-- order_customer_id: integer (nullable = true)\n |-- order_status: string (nullable = true)\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "orders.show()",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+--------+-------------------+-----------------+---------------+\n|order_id|         order_date|order_customer_id|   order_status|\n+--------+-------------------+-----------------+---------------+\n|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n+--------+-------------------+-----------------+---------------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}